from typing import Dict, Optional, Tuple

import pyro
import pyro.distributions as dist
import torch

from .single_confounding_root import Parameters, SingleConfoundingRoot


class ContinuousContextAndTreatment(SingleConfoundingRoot):
    """
    This is a single confounding root Bayesian toy data simulator of the form ğ‘¦ = ğ‘“(ğ‘, ğ‘) + ğœN(0, 1) where
    ğ‘ is a 1d treatment, set by the user, ğ‘ is a 1d context, which is given, and ğ‘“ is a random function,
    parameterised by ğ›™ = (ğœ“â‚€, ğœ“â‚, ğœ“â‚‚, ğœ“â‚ƒ) as follows:

       ğ‘“(ğ‘, ğ‘; ğ›™) = exp  (- (ğ‘ - g(ğ›™, c))Â² / h(ğ›™, c)Â²- Î»ğ‘Â²), Î» >= 0 is a constant <cost_weight>

    The function ğ‘” determines the location of the maximum expected ğ‘¦ and depends on the parameters ğ›™ and the
    context ğ‘. Specifically ğ‘”(ğ›™, ğ‘) =  ğœ“â‚€ + ğœ“â‚*ğ‘ + ğœ“â‚‚*ğ‘Â² and the maximum expected ğ‘¦ is 1, which is
    achieved by setting ğ‘ to ğ‘”(ğ›™, ğ‘).

    The function ğ˜© controls the scale of ğ‘“ and equals ğ˜©(ğ›™, ğ‘) = ğœ“â‚ƒ, i.e. it is independent if the context ğ‘.

    Note:
        We don't place priors on ğ‘ and ğ‘. Although in the fully Bayesian single confounding root scenario
        ğ‘ = ğ‘“(ğ‘) + ğœ€, in the experimental design context we always choose ğ‘, i.e. we do(ğ‘), and so learning
        a distribution for ğ‘ is not necessary.
    """

    def __init__(
        self,
        treatment_policy: torch.nn.Module,
        priors_on_parameters: Dict,
        noise_scale: float = 0.1,
        cost_weight: float = 0.1,
        return_max_reward: bool = True,
    ) -> None:
        """
        Args:
            priors_on_parameters: dict of length 4 containing the priors (pyro.distributions) on the 4 parameters.
                It should be in the form {parameter_name: pyro.distributions}. The parameters ğ›™  are required to be positive.
            noise_scale: Standard deviation (scale) of the noise, ğœ
            cost_weight: penalise large treatments, defaults to 0.1
        """
        super().__init__(
            priors_on_parameters=priors_on_parameters,
            treatment_policy=treatment_policy,
            return_max_reward=return_max_reward,
        )
        self.noise_scale = noise_scale
        self.cost_weight = cost_weight

    def _costless_optimal_treatment(self, parameters: Parameters, context: torch.Tensor) -> torch.Tensor:
        """
        Calculate ğ‘”(ğ›™, ğ‘) =  ğœ“â‚€ + ğœ“â‚*ğ‘ + ğœ“â‚‚*ğ‘Â² which is also the optimal treatment if Î»=0
        Args:
            parameters: sample of size <batch_size> from the (current) prior; each psi{i} is expected to be of shape [batch_size_psi, 1]
                context: 1-d context variable, expected shape [1, batch_size_context] to allow broadcasting.
        Returns:
            A tensor of shape [batch_size_psi, batch_size_context]
        """
        return parameters["psi0"] + parameters["psi1"] * context - parameters["psi2"] * context**2

    def sample_observational_data(
        self,
        parameters: Parameters,
        context: torch.Tensor,
        effect_variable: Optional[str] = "y",
        return_mean: bool = False,
    ) -> torch.Tensor:
        """
        Defines a pyro model to sample sample from the observational distribution ğ‘(ğ‘¦ | ğ‘, ğ‘, ğ›™).

        Args:
            parameters: dict of the form {parameter_name: torch.tensor(value)}--samples of ğ›™ from the current prior.
            context: a one-dimensional context variable.
            treatment: a one-dimensional treatment.
            return_mean: whether to return the mean of the distribution or the sampled outcome; defaults to False
                (i.e. return the observation).

        Returns:
            A sample from ğ‘(ğ‘¦ | ğ‘, ğ‘, ğ›™) or its mean.
        """
        costless_max_location = self._costless_optimal_treatment(parameters, context)
        mean = torch.exp(
            -(((self.treatment_policy() - costless_max_location) / parameters["psi3"]) ** 2)
            - self.cost_weight * self.treatment_policy() ** 2
        )
        y = pyro.sample(effect_variable, dist.Normal(mean, self.noise_scale).to_event(1))
        return mean if return_mean else y

    def calculate_conditional_max_reward(
        self, parameters: Parameters, context: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        The maximum reward is defined as the maximum expected ğ‘¦ oval all possible treatments, i.e.
            ğ‘š(ğ‘ | ğ›™) = max_ğ‘ E[ğ‘¦ | ğ‘, do(ğ‘), ğ›™].
        Since we are dealing with a fixed graph we gave ğ‘š(ğ‘ | ğ›™) = max_ğ‘ E [ğ‘¦ | ğ‘, ğ‘, ğ›™].

        Args:
            parameters: dict of the form {parameter_name: torch.tensor(value)}--samples of ğ›™ from the current prior.
            context: context variable

        Returns: A tuple (max_reward, optimal_treatment) -- <max_reward> is the maximum reward achievable by
            <optimal_treatment>  for the given <context>

        Details on obtaining max reward:
            Note max_ğ‘ E [ğ‘¦ | ğ‘, ğ‘, ğ›™] <=> max_ğ‘ ğ‘“(ğ‘, ğ‘). The derivative with respect to ğ‘ of ğ‘“(ğ‘, ğ‘) is
                ğ‘“' = -2ğ‘“(ğ‘, ğ‘)  ( Î»ğ‘h(ğ›™, c)Â² + ğ‘ - g(ğ›™, c) ) / h(ğ›™, c)Â²
            Setting this to 0 gives us the optimal treatment:
                ğ‘* = g(ğ›™, c) / (1 + Î»*h(ğ›™, c)^2)
            and substituting back in ğ‘“ gives the max reward.
        """

        costless_max_location = self._costless_optimal_treatment(parameters, context)
        optimal_treatment = costless_max_location / (1 + self.cost_weight * parameters["psi3"] ** 2)
        max_reward = torch.exp(
            -(
                (
                    self.cost_weight
                    * parameters["psi3"]
                    * costless_max_location
                    / (1 + self.cost_weight * parameters["psi3"] ** 2)
                )
                ** 2
            )
            - self.cost_weight * optimal_treatment**2
        )
        return max_reward, optimal_treatment
